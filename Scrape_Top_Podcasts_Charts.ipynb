{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from BeautifulSoup import BeautifulSoup\n",
    "import urllib2\n",
    "import unidecode\n",
    "import tqdm\n",
    "import pickle\n",
    "import pycurl\n",
    "import time\n",
    "import guess_language\n",
    "import psycopg2\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from gensim import corpora, models, similarities\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_itunes_charts_ids(url):\n",
    "    r = requests.get(url)\n",
    "    c = r.content\n",
    "    soup = BeautifulSoup(c)\n",
    "    samples = soup.findAll(\"p\", \"buy\")\n",
    "    \n",
    "    ids = []\n",
    "    for s in samples:\n",
    "        s = str(s.contents[0])\n",
    "        ids.append(re.findall(r'/id([\\d]+)', s)[0])\n",
    "    \n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scrape_urls = ['http://www.itunescharts.net/us/charts/podcasts/2016/01/29',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/comedy/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/tv-film/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/technology/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/sport/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/games-hobbies/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/arts/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/music/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/religion-spirituality/',\n",
    "              'http://www.itunescharts.net/us/charts/podcasts/science-medicine/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_ids = []\n",
    "for url in scrape_urls:\n",
    "    ids = get_itunes_charts_ids(url)\n",
    "    all_ids = all_ids + ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "460"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add purrrcast\n",
    "all_ids = all_ids + ['1041016803']\n",
    "\n",
    "# remove duplicates\n",
    "all_ids = list(set(all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# will store pycurl output\n",
    "class Test:\n",
    "   def __init__(self):\n",
    "       self.contents = ''\n",
    "\n",
    "   def body_callback(self, buf):\n",
    "       self.contents = self.contents + buf\n",
    "        \n",
    "def run_curl(url):\n",
    "    t = Test()\n",
    "    c = pycurl.Curl()\n",
    "    c.setopt(pycurl.URL, url)\n",
    "    c.setopt(pycurl.HTTPHEADER, ['X-Apple-Store-Front: 143441-1,12', 'X-Apple-Tz: 3600'])\n",
    "    c.setopt(pycurl.USERAGENT, 'iTunes/9.2.1 (Macintosh; Intel Mac OS X 10.5.8) AppleWebKit/533.16')\n",
    "    c.setopt(pycurl.SSL_VERIFYHOST, 0)\n",
    "    c.setopt(pycurl.SSL_VERIFYPEER, 0)\n",
    "    c.setopt(pycurl.WRITEFUNCTION, t.body_callback)\n",
    "    c.perform()\n",
    "    return t\n",
    "\n",
    "def clean_description(d):\n",
    "    d = unidecode.unidecode(d)\n",
    "    d = d.replace('\\n', ' ')\n",
    "    if re.findall(r'(.*) brought to you by.*', d):\n",
    "       d = re.sub(r'brought to you by.*', '', d)\n",
    "    if re.search(r'(.*) sponsored by.*', d):\n",
    "       d = re.sub(r'sponsored by.*', '', d)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "baseUrl = 'https://itunes.apple.com/us/podcast/id'\n",
    "colNames = ['collectionId', 'podcastSummary', 'episodeNames', 'episodeDescriptions', 'alsoSubscribed']\n",
    "scrapeResults = pd.DataFrame(columns=colNames)\n",
    "\n",
    "for i in tqdm.tqdm(all_ids):\n",
    "    scrapeUrl = baseUrl + str(i)\n",
    "    \n",
    "    # get podcast summary\n",
    "    t = run_curl(scrapeUrl)\n",
    "    soup = BeautifulSoup(t.contents)\n",
    "    p = soup.p\n",
    "    if p:\n",
    "        podcastSummary = soup.p.string\n",
    "    else: # redirect\n",
    "        newUrl = soup.findAll(text=re.compile(r'https'))\n",
    "        try:\n",
    "            newUrl = newUrl[0]\n",
    "            newUrl = re.sub(r'&amp;', r'&', newUrl)\n",
    "\n",
    "            t = run_curl(newUrl)\n",
    "            soup = BeautifulSoup(t.contents)\n",
    "            p = soup.p\n",
    "            if p:\n",
    "                podcastSummary = soup.p.string\n",
    "            else:\n",
    "                podcastSummary = np.nan\n",
    "                episodeNames = np.nan\n",
    "                episodeDescriptions = np.nan\n",
    "                alsoSubscribed = np.nan\n",
    "                thisResult = pd.DataFrame({'collectionId' : int(i),\n",
    "                                          'podcastSummary' : [podcastSummary],\n",
    "                                          'episodeNames' : [episodeNames],\n",
    "                                          'episodeDescriptions' : [episodeDescriptions],\n",
    "                                          'alsoSubscribed' : [alsoSubscribed]})\n",
    "                scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "                continue\n",
    "        except:\n",
    "            podcastSummary = np.nan\n",
    "            episodeNames = np.nan\n",
    "            episodeDescriptions = np.nan\n",
    "            alsoSubscribed = np.nan\n",
    "            thisResult = pd.DataFrame({'collectionId' : int(i),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "            scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)\n",
    "            continue\n",
    "    \n",
    "    # get episode names\n",
    "    episodeData = soup.findAll('button', kind='episode')\n",
    "    try:\n",
    "        episodeNames = [unidecode.unidecode(e['item-name']) for e in episodeData]\n",
    "    except: # no name\n",
    "        episodeNames = np.nan\n",
    "    \n",
    "    # get episode descriptions\n",
    "    try:\n",
    "        episodeDescriptions = [clean_description(e['description']) for e in episodeData]\n",
    "    except: # no description\n",
    "        episodeDescriptions = np.nan\n",
    "    \n",
    "    # get also subscribed podcasts\n",
    "    alsoSubscribed = re.findall(r'adam-id=\"(\\d+)\" aria-label=', t.contents)\n",
    "    try:\n",
    "        alsoSubscribed = [int(x) for x in alsoSubscribed]\n",
    "    except:\n",
    "        alsoSubscribed = np.nan\n",
    "        \n",
    "    # append results\n",
    "    thisResult = pd.DataFrame({'collectionId' : int(i),\n",
    "                                      'podcastSummary' : [podcastSummary],\n",
    "                                      'episodeNames' : [episodeNames],\n",
    "                                      'episodeDescriptions' : [episodeDescriptions],\n",
    "                                      'alsoSubscribed' : [alsoSubscribed]})\n",
    "    scrapeResults = pd.concat([scrapeResults, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the results\n",
    "scrapeResults['episodeDescriptions'] = [unicode(x) for x in scrapeResults['episodeDescriptions']]\n",
    "scrapeResults['episodeNames'] = [unicode(x) for x in scrapeResults['episodeNames']]\n",
    "scrapeResults['podcastSummary'] = [unicode(x) for x in scrapeResults['podcastSummary']]\n",
    "scrapeResults.to_pickle('pkl/itunes_charts_scrape_' + time.strftime(\"%d-%m-%Y\") + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct iTunes API url\n",
    "id_list = scrapeResults['collectionId'].tolist()\n",
    "id_list = [int(x) for x in id_list]\n",
    "\n",
    "api_base_url = 'https://itunes.apple.com/lookup?id=' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colNames = [u'feedUrl',\n",
    " u'contentAdvisoryRating',\n",
    " u'trackRentalPrice',\n",
    " u'collectionExplicitness',\n",
    " u'releaseDate',\n",
    " u'currency',\n",
    " u'artistId',\n",
    " u'trackPrice',\n",
    " u'trackViewUrl',\n",
    " u'genres',\n",
    " u'collectionName',\n",
    " u'collectionId',\n",
    " u'trackId',\n",
    " u'artworkUrl600',\n",
    " u'collectionViewUrl',\n",
    " u'trackCount',\n",
    " u'primaryGenreName',\n",
    " u'collectionPrice',\n",
    " u'trackCensoredName',\n",
    " u'genreIds',\n",
    " u'trackName',\n",
    " u'artistViewUrl',\n",
    " u'kind',\n",
    " u'collectionHdPrice',\n",
    " u'trackHdRentalPrice',\n",
    " u'wrapperType',\n",
    " u'artworkUrl100',\n",
    " u'collectionCensoredName',\n",
    " u'trackHdPrice',\n",
    " u'radioStationUrl',\n",
    " u'artistName',\n",
    " u'artworkUrl60',\n",
    " u'trackExplicitness',\n",
    " u'artworkUrl30',\n",
    " u'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "api_results = pd.DataFrame(columns=colNames)\n",
    "\n",
    "for i in tqdm.tqdm(id_list):\n",
    "    api_url = api_base_url + str(i)\n",
    "    r = requests.get(api_url)\n",
    "    text = r.text\n",
    "    data = json.loads(text)\n",
    "    thisResult = pd.io.json.json_normalize(data['results'])\n",
    "    api_results = pd.concat([api_results, thisResult], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge scrape & api results\n",
    "podcastDf = pd.merge(api_results, scrapeResults, how = 'inner', on = 'collectionId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to int\n",
    "podcastDf['collectionId'] = [int(x) for x in podcastDf['collectionId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# guess language of summary\n",
    "podcastDf['language'] = [guess_language.guessLanguageName(x) for x in podcastDf['podcastSummary']]\n",
    "podcastDf = podcastDf[podcastDf['language'] == 'English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove mixed alphanumeric\n",
    "    text = re.sub(r\"\"\"(?x) # verbose regex\n",
    "                            \\b    # Start of word\n",
    "                            (?=   # Look ahead to ensure that this word contains...\n",
    "                             \\w*  # (after any number of alphanumeric characters)\n",
    "                             \\d   # ...at least one digit.\n",
    "                            )     # End of lookahead\n",
    "                            \\w+   # Match the alphanumeric word\n",
    "                            \\s*   # Match any following whitespace\"\"\", \n",
    "                             \"\", text)\n",
    "    \n",
    "    # remove urls\n",
    "    text = re.sub(r'\\s([\\S]*.com[\\S]*)\\b', '', text)\n",
    "    text = re.sub(r'\\s([\\S]*.org[\\S]*)\\b', '', text)\n",
    "\n",
    "    \n",
    "    \n",
    "    # remove non-alphanumeric, non-space\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', '', text)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# clean episode data\n",
    "episodeDf = podcastDf[['collectionId','episodeDescriptions', 'episodeNames']]\n",
    "episodeDf['episodeDescriptions'] = [x.split(\"\\',\") for x in episodeDf['episodeDescriptions']]\n",
    "episodeDf['episodeNames'] = [x.split(\"\\',\") for x in episodeDf['episodeNames']]\n",
    "\n",
    "clean_episode_description = []\n",
    "for pod in episodeDf['episodeDescriptions']:\n",
    "    clean_list = []\n",
    "    for ep in pod:\n",
    "        clean_list.append(clean_text(ep))\n",
    "    clean_episode_description.append(clean_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "episodeDf['clean_episode_description'] = clean_episode_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "clean_episode_name = []\n",
    "for pod in episodeDf['episodeNames']:\n",
    "    clean_list = []\n",
    "    for ep in pod:\n",
    "        clean_list.append(clean_text(ep))\n",
    "    clean_episode_name.append(clean_list)\n",
    "episodeDf['clean_episode_name'] = clean_episode_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del episodeDf['episodeDescriptions']\n",
    "del episodeDf['episodeNames']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "podcastDf = pd.merge(podcastDf, episodeDf, how = 'inner', on='collectionId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean podcast summary\n",
    "podcastDf['podcastSummary'] = [clean_text(x) for x in podcastDf['podcastSummary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save clean data\n",
    "podcastDf.to_pickle('pkl/clean_podcast_data' + time.strftime(\"%d-%m-%Y\") + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# connect to database\n",
    "dbname = 'podcast'\n",
    "username = 'lindsay'\n",
    "con = psycopg2.connect(database = dbname, user = username)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# upload data to database\n",
    "query_id = \"SELECT id FROM podcast WHERE collection_id = '%s';\"\n",
    "query_update = \"INSERT INTO podcast (artwork_url30, artwork_url60, artwork_url100, artwork_url600, explicit, name, view_url, summary, episode_descriptions, episode_names, collection_id) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s) RETURNING id;\"\n",
    "\n",
    "for ind, thisPod in tqdm.tqdm(podcastDf.iterrows(), total=podcastDf.shape[0]):\n",
    "    \n",
    "    # check if in database\n",
    "    cursor.execute(query_id, (thisPod['collectionId'], ))\n",
    "    result = cursor.fetchall()\n",
    "    \n",
    "    if len(result) == 0:\n",
    "        data = (thisPod['artworkUrl30'], thisPod['artworkUrl60'], thisPod['artworkUrl100'], thisPod['artworkUrl600'], thisPod['contentAdvisoryRating'], thisPod['collectionCensoredName'], thisPod['collectionViewUrl'], thisPod['podcastSummary'], thisPod['clean_episode_description'], thisPod['clean_episode_name'], thisPod['collectionId'])\n",
    "        cursor.execute(query_update, data)\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get back ids\n",
    "query_id = \"SELECT id FROM podcast WHERE collection_id = '%s';\"\n",
    "db_ids = []\n",
    "for ind, thisPod in podcastDf.iterrows():\n",
    "    cursor.execute(query_id, (thisPod['collectionId'], ))\n",
    "    db_ids.append(cursor.fetchall())\n",
    "    \n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_ids = [x[0] for x in db_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_ids = [x[0] for x in db_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "podcastDf['podcast_id'] = db_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 2)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get unique artists\n",
    "artistDf = podcastDf[['artistName', 'artistViewUrl']]\n",
    "artistDf = artistDf.drop_duplicates()\n",
    "artistDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert artist data into artist table\n",
    "query_artist = \"SELECT id FROM artist WHERE name = %s;\"\n",
    "query_insert = \"INSERT INTO artist (view_url, name) VALUES (%s, %s) RETURNING id;\"\n",
    "artist_id = []\n",
    "for ind, row in artistDf.iterrows():\n",
    "    data = (row['artistName'], )\n",
    "    cursor.execute(query_artist, data)\n",
    "    result = cursor.fetchone()[0]\n",
    "    \n",
    "    if result:\n",
    "        artist_id.append(result)\n",
    "    else:\n",
    "        data = (row['artistViewUrl'], row['artistName'])\n",
    "        cursor.execute(query_insert, data)\n",
    "        artist_id.append(cursor.fetchone()[0])\n",
    "        \n",
    "con.commit()\n",
    "artistDf['artist_id'] = artist_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get unique genres\n",
    "genreDf = podcastDf['genres']\n",
    "genreList = []\n",
    "for row in genreDf:\n",
    "    for genre in row:\n",
    "        genreList.append(genre)\n",
    "genreList = list(set(genreList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert genre data into genre table\n",
    "query_genre = \"SELECT * FROM genre WHERE name = %s;\"\n",
    "query_insert = \"INSERT INTO genre (name) VALUES (%s) RETURNING id;\"\n",
    "genre_id = []\n",
    "for item in genreList:\n",
    "    data = (item, )\n",
    "    cursor.execute(query_genre, data)\n",
    "    result = cursor.fetchone()[0]\n",
    "    if result:\n",
    "        genre_id.append(result)\n",
    "        \n",
    "    else:\n",
    "        cursor.execute(query_insert, data)\n",
    "        genre_id.append(cursor.fetchone()[0])\n",
    "con.commit()\n",
    "genreDf = pd.DataFrame({'name' : genreList,\n",
    "                       'genre_id': genre_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "podcast_artist = pd.merge(podcastDf, artistDf, how = 'inner', on = 'artistName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# insert artist id into podcast table\n",
    "query = \"UPDATE podcast SET artist_id=(%s) WHERE id = (%s);\"\n",
    "for ind, row in podcast_artist.iterrows():\n",
    "    data = (row['artist_id'], row['podcast_id'])\n",
    "    cursor.execute(query, data)\n",
    "    con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "podcast_genre = pd.DataFrame(columns=['podcast_id', 'genre_name'])\n",
    "for ind, row in podcastDf.iterrows():\n",
    "    for genre in row['genres']:\n",
    "        \n",
    "        podcast_genre = podcast_genre.append(pd.DataFrame({'podcast_id' : [row['podcast_id']],\n",
    "                                            'genre_name' : [genre]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "podcast_genre = pd.merge(podcast_genre, genreDf, how = 'inner', left_on='genre_name', right_on='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_name</th>\n",
       "      <th>podcast_id</th>\n",
       "      <th>genre_id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arts</td>\n",
       "      <td>18521</td>\n",
       "      <td>205</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arts</td>\n",
       "      <td>13989</td>\n",
       "      <td>205</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arts</td>\n",
       "      <td>18523</td>\n",
       "      <td>205</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arts</td>\n",
       "      <td>18538</td>\n",
       "      <td>205</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arts</td>\n",
       "      <td>18539</td>\n",
       "      <td>205</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  genre_name  podcast_id  genre_id  name\n",
       "0       Arts       18521       205  Arts\n",
       "1       Arts       13989       205  Arts\n",
       "2       Arts       18523       205  Arts\n",
       "3       Arts       18538       205  Arts\n",
       "4       Arts       18539       205  Arts"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_genre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert podcast-genre mappings into podcast_has_genre table\n",
    "query = \"INSERT INTO podcast_has_genre (podcast_id, genre_id) VALUES (%s, %s);\"\n",
    "for ind, row in podcast_genre.iterrows():\n",
    "    data = (row['podcast_id'], row['genre_id'])\n",
    "    cursor.execute(query, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_also_subscribed = podcastDf[['podcast_id', 'alsoSubscribed']]\n",
    "also_subscribed = pd.DataFrame(columns = ['podcast_id', 'also_subscribed'])\n",
    "for ind, row in tmp_also_subscribed.iterrows():\n",
    "    for sub in row['alsoSubscribed']:\n",
    "        also_subscribed = also_subscribed.append(pd.DataFrame({'podcast_id' : [row['podcast_id']],\n",
    "                                                              'also_subscribed' : [sub]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "also_subscribed.rename(columns = {'podcast_id':'initial_podcast_id'}, inplace=True)\n",
    "podcastId = podcastDf[['podcast_id', 'collectionId']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "also_subscribed = pd.merge(also_subscribed, podcastId, how = 'inner', left_on='also_subscribed', right_on='collectionId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert also_subscribed data\n",
    "query = \"INSERT INTO also_subscribed (initial_podcast, subscribed_podcast) VALUES (%s, %s);\"\n",
    "for ind, row in also_subscribed.iterrows():\n",
    "    data = (row['initial_podcast_id'], row['podcast_id'])\n",
    "    cursor.execute(query, data)\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pkl dfs\n",
    "podcastDf.to_pickle('pkl/podcastDf_with_sql_id' + time.strftime(\"%d-%m-%Y\") + '.pkl')\n",
    "artistDf.to_pickle('pkl/artistDf_with_sql_id.pkl' + time.strftime(\"%d-%m-%Y\") + '.pkl')\n",
    "genreDf.to_pickle('pkl/genreDf_with_sql_id.pkl' + time.strftime(\"%d-%m-%Y\") + '.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT id, collection_id, summary, episode_descriptions, episode_names FROM podcast\"\n",
    "cursor.execute(query, con)\n",
    "query_results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query_df = pd.DataFrame({'id' : [x[0] for x in query_results],\n",
    "                         'collection_id' : [x[1] for x in query_results],\n",
    "                         'summary' : [x[2] for x in query_results],\n",
    "                         'episode_descriptions' : [x[3] for x in query_results],\n",
    "                         'episode_names' : [x[4] for x in query_results]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# concatenate text and remove non-alphanumeric characters for each podcast\n",
    "podcast_text = pd.DataFrame(columns=['id', 'collection_id', 'text', 'language'])\n",
    "for ind, row in query_df.iterrows():\n",
    "    # concatenate\n",
    "    text = ' '.join([row['summary'], row['episode_descriptions'], row['episode_names']])\n",
    "    \n",
    "    # remove non-alphanumeric, non-space\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', '', text)\n",
    "    \n",
    "    # guess language of text\n",
    "    language = guess_language.guessLanguageName(text)\n",
    "    \n",
    "    podcast_text = podcast_text.append(pd.DataFrame({'id' : [row['id']],\n",
    "                                                     'collection_id': [row['collection_id']],\n",
    "                                                    'text' : [text],\n",
    "                                                    'language' : [language]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126723118</td>\n",
       "      <td>12350</td>\n",
       "      <td>English</td>\n",
       "      <td>Insurance news interviews rating announcements...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>699748055</td>\n",
       "      <td>12351</td>\n",
       "      <td>English</td>\n",
       "      <td>The Amovetv crew talk video games eSports a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258723953</td>\n",
       "      <td>18521</td>\n",
       "      <td>English</td>\n",
       "      <td>A weekly conversation about whats new in The N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>529175048</td>\n",
       "      <td>12357</td>\n",
       "      <td>English</td>\n",
       "      <td>AfricanAmerican Conservatives focuses on topic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290783428</td>\n",
       "      <td>18527</td>\n",
       "      <td>English</td>\n",
       "      <td>Money makes the world go around faster and fas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_id     id language  \\\n",
       "0      126723118  12350  English   \n",
       "0      699748055  12351  English   \n",
       "0      258723953  18521  English   \n",
       "0      529175048  12357  English   \n",
       "0      290783428  18527  English   \n",
       "\n",
       "                                                text  \n",
       "0  Insurance news interviews rating announcements...  \n",
       "0  The Amovetv crew talk video games eSports a lo...  \n",
       "0  A weekly conversation about whats new in The N...  \n",
       "0  AfricanAmerican Conservatives focuses on topic...  \n",
       "0  Money makes the world go around faster and fas...  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# tokenize text\n",
    "tokenized = podcast_text.copy(deep=True)\n",
    "tokenized['text'] = [tokenizer.tokenize(x.lower()) for x in tokenized['text']]\n",
    "\n",
    "# create list of stop words\n",
    "stop = get_stop_words('en')\n",
    "\n",
    "# remove non-alphanumeric, non-space\n",
    "stop = [re.sub(r'([^\\s\\w]|_)+', '', x) for x in stop]\n",
    "\n",
    "# add in custom stop words\n",
    "days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "months = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "other = ['nan', 'podcast']\n",
    "\n",
    "[stop.append(unicode(day)) for day in days]\n",
    "[stop.append(unicode(month)) for month in months]\n",
    "[stop.append(unicode(x)) for x in other]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_stop(text, stop):\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if word not in stop:\n",
    "            new_text.append(word)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "stopped = tokenized.copy(deep=True)\n",
    "stopped['text'] = [remove_stop(text,stop) for text in stopped['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stem_list(text, p_stemmer):\n",
    "    new_list = []\n",
    "    for word in text:\n",
    "        new_list.append(p_stemmer.stem(word))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stem words\n",
    "p_stemmer = PorterStemmer()\n",
    "stemmed = stopped.copy(deep=True)\n",
    "stemmed['text'] = [stem_list(text, p_stemmer) for text in stemmed['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove tokens containing 'http' or 'www'\n",
    "documents_no_web = pd.DataFrame(columns=stemmed.columns)\n",
    "for ind, row in stemmed.iterrows():\n",
    "    text = row['text']\n",
    "    new_text = []\n",
    "    for word in text:\n",
    "        if re.search(r'http', word):\n",
    "            continue\n",
    "        if re.search(r'www', word):\n",
    "            continue\n",
    "        new_text.append(word)\n",
    "    row['text'] = new_text\n",
    "    documents_no_web = documents_no_web.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>id</th>\n",
       "      <th>language</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126723118</td>\n",
       "      <td>12350</td>\n",
       "      <td>English</td>\n",
       "      <td>[insur, news, interview, rate, announc, insur,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>699748055</td>\n",
       "      <td>12351</td>\n",
       "      <td>English</td>\n",
       "      <td>[amovetv, crew, talk, video, game, esport, lot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258723953</td>\n",
       "      <td>18521</td>\n",
       "      <td>English</td>\n",
       "      <td>[weekli, convers, new, new, yorker, orson, wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>529175048</td>\n",
       "      <td>12357</td>\n",
       "      <td>English</td>\n",
       "      <td>[africanamerican, conserv, focus, topic, relev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>290783428</td>\n",
       "      <td>18527</td>\n",
       "      <td>English</td>\n",
       "      <td>[money, make, world, go, around, faster, faste...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   collection_id     id language  \\\n",
       "0      126723118  12350  English   \n",
       "0      699748055  12351  English   \n",
       "0      258723953  18521  English   \n",
       "0      529175048  12357  English   \n",
       "0      290783428  18527  English   \n",
       "\n",
       "                                                text  \n",
       "0  [insur, news, interview, rate, announc, insur,...  \n",
       "0  [amovetv, crew, talk, video, game, esport, lot...  \n",
       "0  [weekli, convers, new, new, yorker, orson, wel...  \n",
       "0  [africanamerican, conserv, focus, topic, relev...  \n",
       "0  [money, make, world, go, around, faster, faste...  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_no_web.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6136, 4)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_no_web.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load('flask_app/flask_podcast/static/data/dictionary.dict')\n",
    "lsi = models.LsiModel.load('flask_app/flask_podcast/static/data/model.lsi')\n",
    "index = similarities.MatrixSimilarity.load('flask_app/flask_podcast/static/data/tfidf_lsi_similarities.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in documents_no_web['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform to tfidf\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "corpora.MmCorpus.serialize('flask_app/flask_podcast/static/data/corpus_tfidf.mm', corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 s, sys: 3.63 s, total: 32.1 s\n",
      "Wall time: 26.2 s\n"
     ]
    }
   ],
   "source": [
    "# lsi model on tfidf\n",
    "%time lsi = models.lsimodel.LsiModel(corpus_tfidf, num_topics = 100, id2word=dictionary)\n",
    "lsi.save('flask_app/flask_podcast/static/data/model.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.similarities.docsim:scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n"
     ]
    }
   ],
   "source": [
    "# calculate similarities\n",
    "index = similarities.MatrixSimilarity(lsi[corpus_tfidf])\n",
    "index.save('flask_app/flask_podcast/static/data/tfidf_lsi_similarities.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   podcast_id\n",
       "0       18521\n",
       "1       18522\n",
       "2       13989\n",
       "3       18523\n",
       "4       18524"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ids = pd.DataFrame({'podcast_id': podcastDf.podcast_id})\n",
    "new_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_ids.to_pickle('flask_app/flask_podcast/static/data/podcast_id_to_gensim_id.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 1)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_podcasts = pd.read_pickle('pkl/itunes_charts_scrape_07-02-2016.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'alsoSubscribed', u'collectionId', u'episodeDescriptions',\n",
       "       u'episodeNames', u'podcastSummary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_podcasts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                 u'artistId',                u'artistName',\n",
       "                   u'artistViewUrl',             u'artworkUrl100',\n",
       "                    u'artworkUrl30',              u'artworkUrl60',\n",
       "                   u'artworkUrl600',    u'collectionCensoredName',\n",
       "          u'collectionExplicitness',         u'collectionHdPrice',\n",
       "                    u'collectionId',            u'collectionName',\n",
       "                 u'collectionPrice',         u'collectionViewUrl',\n",
       "           u'contentAdvisoryRating',                   u'country',\n",
       "                        u'currency',                   u'feedUrl',\n",
       "                        u'genreIds',                    u'genres',\n",
       "                            u'kind',          u'primaryGenreName',\n",
       "                 u'radioStationUrl',               u'releaseDate',\n",
       "               u'trackCensoredName',                u'trackCount',\n",
       "               u'trackExplicitness',              u'trackHdPrice',\n",
       "              u'trackHdRentalPrice',                   u'trackId',\n",
       "                       u'trackName',                u'trackPrice',\n",
       "                u'trackRentalPrice',              u'trackViewUrl',\n",
       "                     u'wrapperType',            u'alsoSubscribed',\n",
       "             u'episodeDescriptions',              u'episodeNames',\n",
       "                  u'podcastSummary',                  u'language',\n",
       "       u'clean_episode_description',        u'clean_episode_name',\n",
       "                      u'podcast_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcastDf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_podcasts = pd.merge(new_podcasts, podcastDf, how='inner', on='collectionId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alsoSubscribed_x</th>\n",
       "      <th>collectionId</th>\n",
       "      <th>episodeDescriptions_x</th>\n",
       "      <th>episodeNames_x</th>\n",
       "      <th>podcastSummary_x</th>\n",
       "      <th>artistId</th>\n",
       "      <th>artistName</th>\n",
       "      <th>artistViewUrl</th>\n",
       "      <th>artworkUrl100</th>\n",
       "      <th>artworkUrl30</th>\n",
       "      <th>...</th>\n",
       "      <th>trackViewUrl</th>\n",
       "      <th>wrapperType</th>\n",
       "      <th>alsoSubscribed_y</th>\n",
       "      <th>episodeDescriptions_y</th>\n",
       "      <th>episodeNames_y</th>\n",
       "      <th>podcastSummary_y</th>\n",
       "      <th>language</th>\n",
       "      <th>clean_episode_description</th>\n",
       "      <th>clean_episode_name</th>\n",
       "      <th>podcast_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[120315179, 279188498, 158004641, 73330715, 21...</td>\n",
       "      <td>258723953</td>\n",
       "      <td>['Orson Welles was born a hundred years ago, i...</td>\n",
       "      <td>['Beyond \"Citizen Kane\"', 'What it Means to Be...</td>\n",
       "      <td>A weekly conversation about what's new in The ...</td>\n",
       "      <td>331376890</td>\n",
       "      <td>The New Yorker</td>\n",
       "      <td>https://itunes.apple.com/us/artist/the-new-yor...</td>\n",
       "      <td>http://is5.mzstatic.com/image/thumb/Music1/v4/...</td>\n",
       "      <td>http://is5.mzstatic.com/image/thumb/Music1/v4/...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://itunes.apple.com/us/podcast/new-yorker...</td>\n",
       "      <td>track</td>\n",
       "      <td>[120315179, 279188498, 158004641, 73330715, 21...</td>\n",
       "      <td>['Orson Welles was born a hundred years ago, i...</td>\n",
       "      <td>['Beyond \"Citizen Kane\"', 'What it Means to Be...</td>\n",
       "      <td>A weekly conversation about whats new in The N...</td>\n",
       "      <td>English</td>\n",
       "      <td>[Orson Welles was born a hundred years ago in ...</td>\n",
       "      <td>[Beyond Citizen Kane,  What it Means to Be a S...</td>\n",
       "      <td>18521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>1076128054</td>\n",
       "      <td>[\"Join hosts Adam Hlavac, Hector Navarro and A...</td>\n",
       "      <td>['45: Is Apokolips Coming?', '44: Justice Leag...</td>\n",
       "      <td>Welcome to Superhero News! Your source for the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Superhero News</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://is4.mzstatic.com/image/thumb/Music69/v4...</td>\n",
       "      <td>http://is4.mzstatic.com/image/thumb/Music69/v4...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://itunes.apple.com/us/podcast/the-superh...</td>\n",
       "      <td>track</td>\n",
       "      <td>[]</td>\n",
       "      <td>[\"Join hosts Adam Hlavac, Hector Navarro and A...</td>\n",
       "      <td>['45: Is Apokolips Coming?', '44: Justice Leag...</td>\n",
       "      <td>Welcome to Superhero News Your source for the ...</td>\n",
       "      <td>English</td>\n",
       "      <td>[Join hosts Adam Hlavac Hector Navarro and Agu...</td>\n",
       "      <td>[ Is Apokolips Coming,   Justice League Concep...</td>\n",
       "      <td>18522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[84389707, 809264944, 941907967, 490297492, 95...</td>\n",
       "      <td>870688022</td>\n",
       "      <td>['At 63 years old, musician Lucinda Williams i...</td>\n",
       "      <td>['Lucinda Williams Says Whatever the Hell She ...</td>\n",
       "      <td>Death, Sex &amp;amp; Money is a podcast about the ...</td>\n",
       "      <td>127981066</td>\n",
       "      <td>WNYC Studios</td>\n",
       "      <td>https://itunes.apple.com/us/artist/wnyc/id1279...</td>\n",
       "      <td>http://is4.mzstatic.com/image/thumb/Music2/v4/...</td>\n",
       "      <td>http://is4.mzstatic.com/image/thumb/Music2/v4/...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://itunes.apple.com/us/podcast/death-sex-...</td>\n",
       "      <td>track</td>\n",
       "      <td>[84389707, 809264944, 941907967, 490297492, 95...</td>\n",
       "      <td>['At 63 years old, musician Lucinda Williams i...</td>\n",
       "      <td>['Lucinda Williams Says Whatever the Hell She ...</td>\n",
       "      <td>Death Sex amp Money is a podcast about the big...</td>\n",
       "      <td>English</td>\n",
       "      <td>[At years old musician Lucinda Williams is mor...</td>\n",
       "      <td>[Lucinda Williams Says Whatever the Hell She W...</td>\n",
       "      <td>13989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[953290300, 275699983, 394775318, 523121474, 2...</td>\n",
       "      <td>283657561</td>\n",
       "      <td>['All-NEW \"Snap LIVE! in NYC\" featuring Tariq ...</td>\n",
       "      <td>['Snap #703 - Snap LIVE! in NYC', 'Snap #607 -...</td>\n",
       "      <td>Snap Judgment (Storytelling, with a BEAT) mixe...</td>\n",
       "      <td>127981066</td>\n",
       "      <td>Snap Judgment and WNYC Studios</td>\n",
       "      <td>https://itunes.apple.com/us/artist/wnyc/id1279...</td>\n",
       "      <td>http://is5.mzstatic.com/image/thumb/Music6/v4/...</td>\n",
       "      <td>http://is5.mzstatic.com/image/thumb/Music6/v4/...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://itunes.apple.com/us/podcast/snap-judgm...</td>\n",
       "      <td>track</td>\n",
       "      <td>[953290300, 275699983, 394775318, 523121474, 2...</td>\n",
       "      <td>['All-NEW \"Snap LIVE! in NYC\" featuring Tariq ...</td>\n",
       "      <td>['Snap #703 - Snap LIVE! in NYC', 'Snap #607 -...</td>\n",
       "      <td>Snap Judgment Storytelling with a BEAT mixes r...</td>\n",
       "      <td>English</td>\n",
       "      <td>[AllNEW Snap LIVE in NYC featuring Tariq Black...</td>\n",
       "      <td>[Snap  Snap LIVE in NYC,  Snap  infamous,  Sna...</td>\n",
       "      <td>18523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[492735082, 278196007, 74840240, 81210923, 789...</td>\n",
       "      <td>336934080</td>\n",
       "      <td>['FRONTLINE, The New York Times and the Canadi...</td>\n",
       "      <td>['Supplements and Safety', 'Netanyahu at War',...</td>\n",
       "      <td>FRONTLINE presents audio versions of select fu...</td>\n",
       "      <td>127966016</td>\n",
       "      <td>FRONTLINE</td>\n",
       "      <td>https://itunes.apple.com/us/artist/pbs/id12796...</td>\n",
       "      <td>http://is1.mzstatic.com/image/thumb/Music6/v4/...</td>\n",
       "      <td>http://is1.mzstatic.com/image/thumb/Music6/v4/...</td>\n",
       "      <td>...</td>\n",
       "      <td>https://itunes.apple.com/us/podcast/frontline-...</td>\n",
       "      <td>track</td>\n",
       "      <td>[492735082, 278196007, 74840240, 81210923, 789...</td>\n",
       "      <td>['FRONTLINE, The New York Times and the Canadi...</td>\n",
       "      <td>['Supplements and Safety', 'Netanyahu at War',...</td>\n",
       "      <td>FRONTLINE presents audio versions of select fu...</td>\n",
       "      <td>English</td>\n",
       "      <td>[FRONTLINE The New York Times and the Canadian...</td>\n",
       "      <td>[Supplements and Safety,  Netanyahu at War,  M...</td>\n",
       "      <td>18524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    alsoSubscribed_x  collectionId  \\\n",
       "0  [120315179, 279188498, 158004641, 73330715, 21...     258723953   \n",
       "1                                                 []    1076128054   \n",
       "2  [84389707, 809264944, 941907967, 490297492, 95...     870688022   \n",
       "3  [953290300, 275699983, 394775318, 523121474, 2...     283657561   \n",
       "4  [492735082, 278196007, 74840240, 81210923, 789...     336934080   \n",
       "\n",
       "                               episodeDescriptions_x  \\\n",
       "0  ['Orson Welles was born a hundred years ago, i...   \n",
       "1  [\"Join hosts Adam Hlavac, Hector Navarro and A...   \n",
       "2  ['At 63 years old, musician Lucinda Williams i...   \n",
       "3  ['All-NEW \"Snap LIVE! in NYC\" featuring Tariq ...   \n",
       "4  ['FRONTLINE, The New York Times and the Canadi...   \n",
       "\n",
       "                                      episodeNames_x  \\\n",
       "0  ['Beyond \"Citizen Kane\"', 'What it Means to Be...   \n",
       "1  ['45: Is Apokolips Coming?', '44: Justice Leag...   \n",
       "2  ['Lucinda Williams Says Whatever the Hell She ...   \n",
       "3  ['Snap #703 - Snap LIVE! in NYC', 'Snap #607 -...   \n",
       "4  ['Supplements and Safety', 'Netanyahu at War',...   \n",
       "\n",
       "                                    podcastSummary_x   artistId  \\\n",
       "0  A weekly conversation about what's new in The ...  331376890   \n",
       "1  Welcome to Superhero News! Your source for the...        NaN   \n",
       "2  Death, Sex &amp; Money is a podcast about the ...  127981066   \n",
       "3  Snap Judgment (Storytelling, with a BEAT) mixe...  127981066   \n",
       "4  FRONTLINE presents audio versions of select fu...  127966016   \n",
       "\n",
       "                       artistName  \\\n",
       "0                  The New Yorker   \n",
       "1                  Superhero News   \n",
       "2                    WNYC Studios   \n",
       "3  Snap Judgment and WNYC Studios   \n",
       "4                       FRONTLINE   \n",
       "\n",
       "                                       artistViewUrl  \\\n",
       "0  https://itunes.apple.com/us/artist/the-new-yor...   \n",
       "1                                                NaN   \n",
       "2  https://itunes.apple.com/us/artist/wnyc/id1279...   \n",
       "3  https://itunes.apple.com/us/artist/wnyc/id1279...   \n",
       "4  https://itunes.apple.com/us/artist/pbs/id12796...   \n",
       "\n",
       "                                       artworkUrl100  \\\n",
       "0  http://is5.mzstatic.com/image/thumb/Music1/v4/...   \n",
       "1  http://is4.mzstatic.com/image/thumb/Music69/v4...   \n",
       "2  http://is4.mzstatic.com/image/thumb/Music2/v4/...   \n",
       "3  http://is5.mzstatic.com/image/thumb/Music6/v4/...   \n",
       "4  http://is1.mzstatic.com/image/thumb/Music6/v4/...   \n",
       "\n",
       "                                        artworkUrl30    ...      \\\n",
       "0  http://is5.mzstatic.com/image/thumb/Music1/v4/...    ...       \n",
       "1  http://is4.mzstatic.com/image/thumb/Music69/v4...    ...       \n",
       "2  http://is4.mzstatic.com/image/thumb/Music2/v4/...    ...       \n",
       "3  http://is5.mzstatic.com/image/thumb/Music6/v4/...    ...       \n",
       "4  http://is1.mzstatic.com/image/thumb/Music6/v4/...    ...       \n",
       "\n",
       "                                        trackViewUrl wrapperType  \\\n",
       "0  https://itunes.apple.com/us/podcast/new-yorker...       track   \n",
       "1  https://itunes.apple.com/us/podcast/the-superh...       track   \n",
       "2  https://itunes.apple.com/us/podcast/death-sex-...       track   \n",
       "3  https://itunes.apple.com/us/podcast/snap-judgm...       track   \n",
       "4  https://itunes.apple.com/us/podcast/frontline-...       track   \n",
       "\n",
       "                                    alsoSubscribed_y  \\\n",
       "0  [120315179, 279188498, 158004641, 73330715, 21...   \n",
       "1                                                 []   \n",
       "2  [84389707, 809264944, 941907967, 490297492, 95...   \n",
       "3  [953290300, 275699983, 394775318, 523121474, 2...   \n",
       "4  [492735082, 278196007, 74840240, 81210923, 789...   \n",
       "\n",
       "                               episodeDescriptions_y  \\\n",
       "0  ['Orson Welles was born a hundred years ago, i...   \n",
       "1  [\"Join hosts Adam Hlavac, Hector Navarro and A...   \n",
       "2  ['At 63 years old, musician Lucinda Williams i...   \n",
       "3  ['All-NEW \"Snap LIVE! in NYC\" featuring Tariq ...   \n",
       "4  ['FRONTLINE, The New York Times and the Canadi...   \n",
       "\n",
       "                                      episodeNames_y  \\\n",
       "0  ['Beyond \"Citizen Kane\"', 'What it Means to Be...   \n",
       "1  ['45: Is Apokolips Coming?', '44: Justice Leag...   \n",
       "2  ['Lucinda Williams Says Whatever the Hell She ...   \n",
       "3  ['Snap #703 - Snap LIVE! in NYC', 'Snap #607 -...   \n",
       "4  ['Supplements and Safety', 'Netanyahu at War',...   \n",
       "\n",
       "                                    podcastSummary_y  language  \\\n",
       "0  A weekly conversation about whats new in The N...   English   \n",
       "1  Welcome to Superhero News Your source for the ...   English   \n",
       "2  Death Sex amp Money is a podcast about the big...   English   \n",
       "3  Snap Judgment Storytelling with a BEAT mixes r...   English   \n",
       "4  FRONTLINE presents audio versions of select fu...   English   \n",
       "\n",
       "                           clean_episode_description  \\\n",
       "0  [Orson Welles was born a hundred years ago in ...   \n",
       "1  [Join hosts Adam Hlavac Hector Navarro and Agu...   \n",
       "2  [At years old musician Lucinda Williams is mor...   \n",
       "3  [AllNEW Snap LIVE in NYC featuring Tariq Black...   \n",
       "4  [FRONTLINE The New York Times and the Canadian...   \n",
       "\n",
       "                                  clean_episode_name podcast_id  \n",
       "0  [Beyond Citizen Kane,  What it Means to Be a S...      18521  \n",
       "1  [ Is Apokolips Coming,   Justice League Concep...      18522  \n",
       "2  [Lucinda Williams Says Whatever the Hell She W...      13989  \n",
       "3  [Snap  Snap LIVE in NYC,  Snap  infamous,  Sna...      18523  \n",
       "4  [Supplements and Safety,  Netanyahu at War,  M...      18524  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_podcasts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "UPDATE podcast\n",
    "SET raw_summary = (%s)\n",
    "WHERE id = (%s);\n",
    "\"\"\"\n",
    "query = query.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "for ind, row in tqdm.tqdm(new_podcasts.iterrows(), total=new_podcasts.shape[0]):\n",
    "    data = ((row['podcastSummary_x'], ), (row['podcast_id'], ))\n",
    "    cursor.execute(query, data)\n",
    "    \n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = \"SELECT clean_name, id FROM podcast;\"\n",
    "matching_results = pd.read_sql_query(query, con)\n",
    "matching_results['clean_name'] = [x.decode('utf-8') for x in matching_results['clean_name']]\n",
    "matching_results['clean_name'] = [x.replace('\"', \"'\") for x in matching_results['clean_name']]\n",
    "match_json = matching_results.to_json(None,\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"SELECT id, collection_id FROM podcast;\"\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6136"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_mapping = pd.DataFrame({'podcast_id' : [x[0] for x in results],\n",
    "                           'collection_id' : [x[1] for x in results]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection_id</th>\n",
       "      <th>podcast_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>258723953</td>\n",
       "      <td>18521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1076128054</td>\n",
       "      <td>18522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126723118</td>\n",
       "      <td>12350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699748055</td>\n",
       "      <td>12351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>775174336</td>\n",
       "      <td>18373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>870688022</td>\n",
       "      <td>13989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>283657561</td>\n",
       "      <td>18523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>276268226</td>\n",
       "      <td>18525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>529175048</td>\n",
       "      <td>12357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>336934080</td>\n",
       "      <td>18524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1065298161</td>\n",
       "      <td>18526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>523428351</td>\n",
       "      <td>17361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>290783428</td>\n",
       "      <td>18527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>942777522</td>\n",
       "      <td>18528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>977764092</td>\n",
       "      <td>18529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>995039015</td>\n",
       "      <td>18530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>733126312</td>\n",
       "      <td>14262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>314020330</td>\n",
       "      <td>18531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>981915381</td>\n",
       "      <td>18533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>218290471</td>\n",
       "      <td>18534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1071545581</td>\n",
       "      <td>18538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>886991360</td>\n",
       "      <td>18302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>274771117</td>\n",
       "      <td>12376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>289105827</td>\n",
       "      <td>18539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1044840362</td>\n",
       "      <td>18541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>991930026</td>\n",
       "      <td>18542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>596796439</td>\n",
       "      <td>12380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>511265415</td>\n",
       "      <td>18543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>425328515</td>\n",
       "      <td>16382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>394775318</td>\n",
       "      <td>16357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6106</th>\n",
       "      <td>602497287</td>\n",
       "      <td>18472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6107</th>\n",
       "      <td>251492592</td>\n",
       "      <td>18473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>525502361</td>\n",
       "      <td>18474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6109</th>\n",
       "      <td>492291786</td>\n",
       "      <td>18475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>502327691</td>\n",
       "      <td>18477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6111</th>\n",
       "      <td>660992101</td>\n",
       "      <td>18479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6112</th>\n",
       "      <td>714920418</td>\n",
       "      <td>18480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6113</th>\n",
       "      <td>563650754</td>\n",
       "      <td>18482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6114</th>\n",
       "      <td>780572890</td>\n",
       "      <td>18485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6115</th>\n",
       "      <td>780574660</td>\n",
       "      <td>18486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6116</th>\n",
       "      <td>611174419</td>\n",
       "      <td>18487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6117</th>\n",
       "      <td>439735399</td>\n",
       "      <td>18490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6118</th>\n",
       "      <td>386941632</td>\n",
       "      <td>18491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6119</th>\n",
       "      <td>894466729</td>\n",
       "      <td>18492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>73900363</td>\n",
       "      <td>18493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6121</th>\n",
       "      <td>380118647</td>\n",
       "      <td>18495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6122</th>\n",
       "      <td>128594474</td>\n",
       "      <td>18500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6123</th>\n",
       "      <td>422532185</td>\n",
       "      <td>18501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>878554955</td>\n",
       "      <td>18502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6125</th>\n",
       "      <td>789762074</td>\n",
       "      <td>18503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6126</th>\n",
       "      <td>516951844</td>\n",
       "      <td>18504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6127</th>\n",
       "      <td>220058832</td>\n",
       "      <td>18505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>348824219</td>\n",
       "      <td>18506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6129</th>\n",
       "      <td>348824357</td>\n",
       "      <td>18507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6130</th>\n",
       "      <td>488810869</td>\n",
       "      <td>18508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6131</th>\n",
       "      <td>372942863</td>\n",
       "      <td>18509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6132</th>\n",
       "      <td>886045028</td>\n",
       "      <td>18510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6133</th>\n",
       "      <td>652149995</td>\n",
       "      <td>18512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6134</th>\n",
       "      <td>319868584</td>\n",
       "      <td>18513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6135</th>\n",
       "      <td>562755631</td>\n",
       "      <td>18514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6136 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      collection_id  podcast_id\n",
       "0         258723953       18521\n",
       "1        1076128054       18522\n",
       "2         126723118       12350\n",
       "3         699748055       12351\n",
       "4         775174336       18373\n",
       "5         870688022       13989\n",
       "6         283657561       18523\n",
       "7         276268226       18525\n",
       "8         529175048       12357\n",
       "9         336934080       18524\n",
       "10       1065298161       18526\n",
       "11        523428351       17361\n",
       "12        290783428       18527\n",
       "13        942777522       18528\n",
       "14        977764092       18529\n",
       "15        995039015       18530\n",
       "16        733126312       14262\n",
       "17        314020330       18531\n",
       "18        981915381       18533\n",
       "19        218290471       18534\n",
       "20       1071545581       18538\n",
       "21        886991360       18302\n",
       "22        274771117       12376\n",
       "23        289105827       18539\n",
       "24       1044840362       18541\n",
       "25        991930026       18542\n",
       "26        596796439       12380\n",
       "27        511265415       18543\n",
       "28        425328515       16382\n",
       "29        394775318       16357\n",
       "...             ...         ...\n",
       "6106      602497287       18472\n",
       "6107      251492592       18473\n",
       "6108      525502361       18474\n",
       "6109      492291786       18475\n",
       "6110      502327691       18477\n",
       "6111      660992101       18479\n",
       "6112      714920418       18480\n",
       "6113      563650754       18482\n",
       "6114      780572890       18485\n",
       "6115      780574660       18486\n",
       "6116      611174419       18487\n",
       "6117      439735399       18490\n",
       "6118      386941632       18491\n",
       "6119      894466729       18492\n",
       "6120       73900363       18493\n",
       "6121      380118647       18495\n",
       "6122      128594474       18500\n",
       "6123      422532185       18501\n",
       "6124      878554955       18502\n",
       "6125      789762074       18503\n",
       "6126      516951844       18504\n",
       "6127      220058832       18505\n",
       "6128      348824219       18506\n",
       "6129      348824357       18507\n",
       "6130      488810869       18508\n",
       "6131      372942863       18509\n",
       "6132      886045028       18510\n",
       "6133      652149995       18512\n",
       "6134      319868584       18513\n",
       "6135      562755631       18514\n",
       "\n",
       "[6136 rows x 2 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6136, 4)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_no_web.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_mapping = pd.DataFrame({'podcast_id' : documents_no_web['id'].tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "id_mapping.to_pickle('flask_app/flask_podcast/static/data/podcast_id_to_gensim_id.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
